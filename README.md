This repository contains a deepfake video detection model implemented using a combination of Long Short-Term Memory (LSTM) and Residual Next (ResNeXt) neural networks. The model aims to tackle the growing threat of deepfake videos, which are manipulated videos created using advanced artificial intelligence techniques.

Deepfake videos have raised concerns due to their potential for misuse, including spreading misinformation, impersonation, and undermining trust in media content. Therefore, it has become crucial to develop robust algorithms that can detect and identify deepfake videos accurately.

The model architecture leverages the power of LSTM and ResNeXt networks to capture temporal dependencies and extract high-level features from video frames. LSTM, a type of recurrent neural network (RNN), is employed to model the temporal dynamics and context in the video sequences. On the other hand, ResNeXt, an advanced convolutional neural network (CNN), is used to learn spatial features and patterns within individual frames.
Visit this link for the reseach paper https://www.ijsrd.com/articles/IJSRDV8I10860.pdf.
